{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing\n",
    "Try different models to see which perform best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from lmfit import Model\n",
    "from xgboost import XGBRegressor\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "from sklearn.feature_selection import f_regression\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "pl.style.use('seaborn')\n",
    "pl.rc('font',family='Arial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in and shape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"SubCh1_TrainingData.csv\")\n",
    "\n",
    "# train data:\n",
    "train_data['Timepoint'] = [1 if i == '24HR' else 0 for i in train_data['Timepoint']]\n",
    "train_data['Treatment'] = [1 if i == 'DHA' else 0 for i in train_data['Treatment']]\n",
    "train_data['BioRep'] = [int(i[-1]) for i in train_data['BioRep']]\n",
    "\n",
    "# generate list of gene names:\n",
    "genes = list(train_data.drop(['DHA_IC50','Sample_Name','Isolate','Timepoint','Treatment','BioRep'], axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>...</th>\n",
       "      <th>D5531</th>\n",
       "      <th>D5532</th>\n",
       "      <th>D5533</th>\n",
       "      <th>D5534</th>\n",
       "      <th>D5535</th>\n",
       "      <th>D5536</th>\n",
       "      <th>D5537</th>\n",
       "      <th>D5538</th>\n",
       "      <th>D5539</th>\n",
       "      <th>D5540</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.311350</td>\n",
       "      <td>-1.613464</td>\n",
       "      <td>-1.298663</td>\n",
       "      <td>-1.441343</td>\n",
       "      <td>-1.735923</td>\n",
       "      <td>0.173112</td>\n",
       "      <td>2.466366</td>\n",
       "      <td>1.383979</td>\n",
       "      <td>-0.115130</td>\n",
       "      <td>0.287468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210607</td>\n",
       "      <td>-0.540993</td>\n",
       "      <td>-3.674097</td>\n",
       "      <td>-1.652979</td>\n",
       "      <td>-2.255490</td>\n",
       "      <td>-4.554757</td>\n",
       "      <td>-0.381422</td>\n",
       "      <td>-1.415857</td>\n",
       "      <td>-4.121011</td>\n",
       "      <td>-2.486528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997722</td>\n",
       "      <td>-1.553994</td>\n",
       "      <td>-1.960600</td>\n",
       "      <td>-1.424590</td>\n",
       "      <td>0.023609</td>\n",
       "      <td>0.420973</td>\n",
       "      <td>1.128427</td>\n",
       "      <td>0.722659</td>\n",
       "      <td>1.878123</td>\n",
       "      <td>-0.065159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447109</td>\n",
       "      <td>0.450649</td>\n",
       "      <td>-4.464408</td>\n",
       "      <td>-0.977954</td>\n",
       "      <td>-2.012559</td>\n",
       "      <td>-4.538550</td>\n",
       "      <td>-2.333890</td>\n",
       "      <td>-2.342496</td>\n",
       "      <td>-4.774197</td>\n",
       "      <td>-1.794568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.389508</td>\n",
       "      <td>-2.139782</td>\n",
       "      <td>-0.584985</td>\n",
       "      <td>-1.085373</td>\n",
       "      <td>0.803247</td>\n",
       "      <td>0.766617</td>\n",
       "      <td>1.701689</td>\n",
       "      <td>0.926101</td>\n",
       "      <td>1.600687</td>\n",
       "      <td>0.435633</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070151</td>\n",
       "      <td>0.024133</td>\n",
       "      <td>-2.215227</td>\n",
       "      <td>-1.957654</td>\n",
       "      <td>-2.188635</td>\n",
       "      <td>-4.424748</td>\n",
       "      <td>-2.986927</td>\n",
       "      <td>-1.722201</td>\n",
       "      <td>-3.995680</td>\n",
       "      <td>-0.902979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.348560</td>\n",
       "      <td>-1.562540</td>\n",
       "      <td>-0.586732</td>\n",
       "      <td>-0.834661</td>\n",
       "      <td>1.096979</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>1.623373</td>\n",
       "      <td>-0.654405</td>\n",
       "      <td>0.221121</td>\n",
       "      <td>0.998601</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.288305</td>\n",
       "      <td>0.806314</td>\n",
       "      <td>-3.733712</td>\n",
       "      <td>-1.990368</td>\n",
       "      <td>-1.633418</td>\n",
       "      <td>-5.533077</td>\n",
       "      <td>-3.283316</td>\n",
       "      <td>-2.104227</td>\n",
       "      <td>-5.767710</td>\n",
       "      <td>-2.177930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.138276</td>\n",
       "      <td>-1.612280</td>\n",
       "      <td>-1.362990</td>\n",
       "      <td>-1.360318</td>\n",
       "      <td>0.488124</td>\n",
       "      <td>0.365410</td>\n",
       "      <td>0.739845</td>\n",
       "      <td>-0.654702</td>\n",
       "      <td>2.170263</td>\n",
       "      <td>0.630418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279816</td>\n",
       "      <td>0.115002</td>\n",
       "      <td>-1.305902</td>\n",
       "      <td>-0.679212</td>\n",
       "      <td>-2.099512</td>\n",
       "      <td>-5.955507</td>\n",
       "      <td>-0.920594</td>\n",
       "      <td>-1.626372</td>\n",
       "      <td>-4.422711</td>\n",
       "      <td>-1.408485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.332565</td>\n",
       "      <td>-1.280348</td>\n",
       "      <td>-0.817751</td>\n",
       "      <td>-0.480521</td>\n",
       "      <td>-0.098970</td>\n",
       "      <td>0.112246</td>\n",
       "      <td>0.773993</td>\n",
       "      <td>-0.969944</td>\n",
       "      <td>1.117705</td>\n",
       "      <td>0.872166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375290</td>\n",
       "      <td>1.113241</td>\n",
       "      <td>-4.016287</td>\n",
       "      <td>-1.327287</td>\n",
       "      <td>-2.375500</td>\n",
       "      <td>-4.379304</td>\n",
       "      <td>-2.752906</td>\n",
       "      <td>-1.939162</td>\n",
       "      <td>-3.500963</td>\n",
       "      <td>-0.796143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.140942</td>\n",
       "      <td>-0.460872</td>\n",
       "      <td>0.588564</td>\n",
       "      <td>-1.214647</td>\n",
       "      <td>1.210955</td>\n",
       "      <td>1.336895</td>\n",
       "      <td>-0.857090</td>\n",
       "      <td>-1.884711</td>\n",
       "      <td>-0.001943</td>\n",
       "      <td>1.320737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666558</td>\n",
       "      <td>-2.016912</td>\n",
       "      <td>-4.682891</td>\n",
       "      <td>-0.254524</td>\n",
       "      <td>-2.668047</td>\n",
       "      <td>-6.573239</td>\n",
       "      <td>-3.264155</td>\n",
       "      <td>-0.671344</td>\n",
       "      <td>-5.312867</td>\n",
       "      <td>-2.248219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.426584</td>\n",
       "      <td>-1.118851</td>\n",
       "      <td>-0.938263</td>\n",
       "      <td>-1.442067</td>\n",
       "      <td>0.747063</td>\n",
       "      <td>0.268388</td>\n",
       "      <td>1.062841</td>\n",
       "      <td>0.494635</td>\n",
       "      <td>0.866481</td>\n",
       "      <td>0.501923</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.793459</td>\n",
       "      <td>-0.116719</td>\n",
       "      <td>-4.535173</td>\n",
       "      <td>-0.537190</td>\n",
       "      <td>-2.472669</td>\n",
       "      <td>-6.261742</td>\n",
       "      <td>-3.134708</td>\n",
       "      <td>-1.969545</td>\n",
       "      <td>-5.157691</td>\n",
       "      <td>-2.637917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.037085</td>\n",
       "      <td>-1.488644</td>\n",
       "      <td>-1.838770</td>\n",
       "      <td>-1.066493</td>\n",
       "      <td>-1.305085</td>\n",
       "      <td>0.059484</td>\n",
       "      <td>2.128986</td>\n",
       "      <td>-0.527511</td>\n",
       "      <td>1.616871</td>\n",
       "      <td>0.235093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478144</td>\n",
       "      <td>0.125283</td>\n",
       "      <td>-5.360958</td>\n",
       "      <td>-2.386122</td>\n",
       "      <td>-1.886257</td>\n",
       "      <td>-6.127057</td>\n",
       "      <td>-3.231487</td>\n",
       "      <td>-2.349583</td>\n",
       "      <td>-4.977880</td>\n",
       "      <td>-1.047555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.037537</td>\n",
       "      <td>-1.495531</td>\n",
       "      <td>-1.801568</td>\n",
       "      <td>-0.526676</td>\n",
       "      <td>-1.831555</td>\n",
       "      <td>0.494413</td>\n",
       "      <td>1.286978</td>\n",
       "      <td>-1.589983</td>\n",
       "      <td>1.060466</td>\n",
       "      <td>0.836018</td>\n",
       "      <td>...</td>\n",
       "      <td>1.213397</td>\n",
       "      <td>-1.032989</td>\n",
       "      <td>-8.298501</td>\n",
       "      <td>-0.080207</td>\n",
       "      <td>-2.335635</td>\n",
       "      <td>-4.606785</td>\n",
       "      <td>-2.849864</td>\n",
       "      <td>-2.028372</td>\n",
       "      <td>-3.179649</td>\n",
       "      <td>-2.205214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A1        A2        A3        A4        A5        A6        A7  \\\n",
       "0  1.311350 -1.613464 -1.298663 -1.441343 -1.735923  0.173112  2.466366   \n",
       "1  0.997722 -1.553994 -1.960600 -1.424590  0.023609  0.420973  1.128427   \n",
       "2  0.389508 -2.139782 -0.584985 -1.085373  0.803247  0.766617  1.701689   \n",
       "3  0.348560 -1.562540 -0.586732 -0.834661  1.096979  0.121817  1.623373   \n",
       "4  0.138276 -1.612280 -1.362990 -1.360318  0.488124  0.365410  0.739845   \n",
       "5 -0.332565 -1.280348 -0.817751 -0.480521 -0.098970  0.112246  0.773993   \n",
       "6 -1.140942 -0.460872  0.588564 -1.214647  1.210955  1.336895 -0.857090   \n",
       "7  0.426584 -1.118851 -0.938263 -1.442067  0.747063  0.268388  1.062841   \n",
       "8  0.037085 -1.488644 -1.838770 -1.066493 -1.305085  0.059484  2.128986   \n",
       "9 -0.037537 -1.495531 -1.801568 -0.526676 -1.831555  0.494413  1.286978   \n",
       "\n",
       "         A8        A9       A10    ...        D5531     D5532     D5533  \\\n",
       "0  1.383979 -0.115130  0.287468    ...     0.210607 -0.540993 -3.674097   \n",
       "1  0.722659  1.878123 -0.065159    ...    -0.447109  0.450649 -4.464408   \n",
       "2  0.926101  1.600687  0.435633    ...    -0.070151  0.024133 -2.215227   \n",
       "3 -0.654405  0.221121  0.998601    ...    -1.288305  0.806314 -3.733712   \n",
       "4 -0.654702  2.170263  0.630418    ...     0.279816  0.115002 -1.305902   \n",
       "5 -0.969944  1.117705  0.872166    ...     0.375290  1.113241 -4.016287   \n",
       "6 -1.884711 -0.001943  1.320737    ...     0.666558 -2.016912 -4.682891   \n",
       "7  0.494635  0.866481  0.501923    ...    -1.793459 -0.116719 -4.535173   \n",
       "8 -0.527511  1.616871  0.235093    ...    -0.478144  0.125283 -5.360958   \n",
       "9 -1.589983  1.060466  0.836018    ...     1.213397 -1.032989 -8.298501   \n",
       "\n",
       "      D5534     D5535     D5536     D5537     D5538     D5539     D5540  \n",
       "0 -1.652979 -2.255490 -4.554757 -0.381422 -1.415857 -4.121011 -2.486528  \n",
       "1 -0.977954 -2.012559 -4.538550 -2.333890 -2.342496 -4.774197 -1.794568  \n",
       "2 -1.957654 -2.188635 -4.424748 -2.986927 -1.722201 -3.995680 -0.902979  \n",
       "3 -1.990368 -1.633418 -5.533077 -3.283316 -2.104227 -5.767710 -2.177930  \n",
       "4 -0.679212 -2.099512 -5.955507 -0.920594 -1.626372 -4.422711 -1.408485  \n",
       "5 -1.327287 -2.375500 -4.379304 -2.752906 -1.939162 -3.500963 -0.796143  \n",
       "6 -0.254524 -2.668047 -6.573239 -3.264155 -0.671344 -5.312867 -2.248219  \n",
       "7 -0.537190 -2.472669 -6.261742 -3.134708 -1.969545 -5.157691 -2.637917  \n",
       "8 -2.386122 -1.886257 -6.127057 -3.231487 -2.349583 -4.977880 -1.047555  \n",
       "9 -0.080207 -2.335635 -4.606785 -2.849864 -2.028372 -3.179649 -2.205214  \n",
       "\n",
       "[10 rows x 22160 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split train data:\n",
    "X_A = train_data[(train_data['Timepoint'] == 0)&(train_data['Treatment'] == 0)].drop(['DHA_IC50','Sample_Name','Isolate','Timepoint','Treatment','BioRep'], axis = 1)\n",
    "X_B = train_data[(train_data['Timepoint'] == 1)&(train_data['Treatment'] == 0)].drop(['DHA_IC50','Sample_Name','Isolate','Timepoint','Treatment','BioRep'], axis = 1)\n",
    "X_C = train_data[(train_data['Timepoint'] == 0)&(train_data['Treatment'] == 1)].drop(['DHA_IC50','Sample_Name','Isolate','Timepoint','Treatment','BioRep'], axis = 1)\n",
    "X_D = train_data[(train_data['Timepoint'] == 1)&(train_data['Treatment'] == 1)].drop(['DHA_IC50','Sample_Name','Isolate','Timepoint','Treatment','BioRep'], axis = 1)\n",
    "\n",
    "# pull out target feature:\n",
    "Y = train_data[(train_data['Timepoint'] == 0)&(train_data['Treatment'] == 0)]['DHA_IC50']\n",
    "\n",
    "# extract biorep feature:\n",
    "bioreps = train_data[(train_data['Timepoint'] == 0)&(train_data['Treatment'] == 0)]['BioRep']\n",
    "\n",
    "# rename train data columns:\n",
    "X_A.columns = ['A' + str(i) for i in range(1,5541)]\n",
    "X_B.columns = ['B' + str(i) for i in range(1,5541)]\n",
    "X_C.columns = ['C' + str(i) for i in range(1,5541)]\n",
    "X_D.columns = ['D' + str(i) for i in range(1,5541)]\n",
    "\n",
    "# reset indices\n",
    "X_A = X_A.reset_index().drop(['index'],axis=1)\n",
    "X_B = X_B.reset_index().drop(['index'],axis=1)\n",
    "X_C = X_C.reset_index().drop(['index'],axis=1)\n",
    "X_D = X_D.reset_index().drop(['index'],axis=1)\n",
    "\n",
    "# combine data frames:\n",
    "X = pd.concat([X_A,X_B,X_C,X_D], axis=1)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_univ(X_orig, Y, features):\n",
    "    X = StandardScaler().fit_transform(X_orig)\n",
    "    X_uni = GenericUnivariateSelect(f_regression,'k_best', param=features).fit_transform(X, Y.values.ravel())\n",
    "    X_uni = pd.DataFrame(data = X_uni)\n",
    "\n",
    "    return X_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale and transform data\n",
    "X_s = StandardScaler().fit_transform(X)\n",
    "transformer = GenericUnivariateSelect(f_regression,'k_best', param=70)\n",
    "X_uni = transformer.fit_transform(X_s, Y.values.ravel())\n",
    "X_uni = pd.DataFrame(data = X_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Define metric and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spear_r(y_true, y_pred):\n",
    "    return spearmanr(y_true, y_pred)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test , Y_train , Y_test = train_test_split(X_uni,Y,test_size=0.33,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.31850268822322364\n",
      "accuracy: -0.24787444027216177\n",
      "spearman: 0.47694883162960167\n",
      "cv score: -0.10997663308315149\n",
      "cv spear: 0.42408328160562\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, Y_train)\n",
    "Y_pred = linear_model.predict(X_test)\n",
    "\n",
    "linear_model_mse = mean_squared_error(Y_test, Y_pred)\n",
    "linear_model_spear = spearmanr(Y_test,Y_pred)[0]\n",
    "linear_model_cv = np.mean(cross_val_score(linear_model, X_train, Y_train.values.ravel(), cv=5))\n",
    "linear_model_cvspear = np.mean(cross_val_score(linear_model, X_train, Y_train.values.ravel(), cv=5,scoring=make_scorer(spear_r)))\n",
    "\n",
    "print('mse: ' + str(mean_squared_error(Y_test, Y_pred)))\n",
    "print('accuracy: ' + str(linear_model.score(X_test,Y_test)))\n",
    "print('spearman: ' + str(spearmanr(Y_test,Y_pred)[0]))\n",
    "print('cv score: ' + str(linear_model_cv))\n",
    "print('cv spear: ' + str(linear_model_cvspear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.14672944368566893\n",
      "accuracy: 0.42512283512541765\n",
      "spearman: 0.5111582592620783\n",
      "cv score: 0.3490669215921106\n",
      "cv spear: 0.5829288774372416\n"
     ]
    }
   ],
   "source": [
    "svr_model = SVR()\n",
    "svr_model.fit(X_train, Y_train.values.ravel())\n",
    "Y_pred = svr_model.predict(X_test)\n",
    "\n",
    "svr_model_mse = mean_squared_error(Y_test, Y_pred)\n",
    "svr_model_spear = spearmanr(Y_test,Y_pred)[0]\n",
    "svr_model_cv = np.mean(cross_val_score(svr_model, X_train, Y_train.values.ravel(), cv=5))\n",
    "svr_model_cvspear = np.mean(cross_val_score(svr_model, X_train, Y_train.values.ravel(), cv=5,scoring=make_scorer(spear_r)))\n",
    "\n",
    "print('mse: ' + str(mean_squared_error(Y_test, Y_pred)))\n",
    "print('accuracy: ' + str(svr_model.score(X_test,Y_test)))\n",
    "print('spearman: ' + str(spearmanr(Y_test,Y_pred)[0]))\n",
    "print('cv score: ' + str(svr_model_cv))\n",
    "print('cv spear: ' + str(svr_model_cvspear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.17207615458826678\n",
      "accuracy: 0.3258159411812387\n",
      "spearman: 0.3673795054444229\n",
      "cv score: 0.3541218783735642\n",
      "cv spear: 0.6096802883668038\n"
     ]
    }
   ],
   "source": [
    "knn_model = neighbors.KNeighborsRegressor(5,weights='distance')\n",
    "knn_model.fit(X_train, Y_train.values.ravel())\n",
    "Y_pred = knn_model.predict(X_test)\n",
    "\n",
    "knn_model_mse = mean_squared_error(Y_test, Y_pred)\n",
    "knn_model_spear = spearmanr(Y_test,Y_pred)[0]\n",
    "knn_model_cv = np.mean(cross_val_score(knn_model, X_train, Y_train.values.ravel(), cv=5))\n",
    "knn_model_cvspear = np.mean(cross_val_score(knn_model, X_train, Y_train.values.ravel(), cv=5,scoring=make_scorer(spear_r)))\n",
    "\n",
    "print('mse: ' + str(mean_squared_error(Y_test, Y_pred)))\n",
    "print('accuracy: ' + str(knn_model.score(X_test,Y_test)))\n",
    "print('spearman: ' + str(spearmanr(Y_test,Y_pred)[0]))\n",
    "print('cv score: ' + str(knn_model_cv))\n",
    "print('cv spear: ' + str(knn_model_cvspear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.6720055208695652\n",
      "accuracy: -1.6328773483606862\n",
      "spearman: 0.022376929668638877\n",
      "cv score: 0.0279993467107968\n",
      "cv spear: 0.38097910624415154\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeRegressor(max_depth=50)\n",
    "tree_model.fit(X_train, Y_train)\n",
    "Y_pred = tree_model.predict(X_test)\n",
    "\n",
    "tree_model_mse = mean_squared_error(Y_test, Y_pred)\n",
    "tree_model_spear = spearmanr(Y_test,Y_pred)[0]\n",
    "tree_model_cv = np.mean(cross_val_score(tree_model, X_train, Y_train.values.ravel(), cv=5))\n",
    "tree_model_cvspear = np.mean(cross_val_score(tree_model, X_train, Y_train.values.ravel(), cv=5,scoring=make_scorer(spear_r)))\n",
    "\n",
    "print('mse: ' + str(mean_squared_error(Y_test, Y_pred)))\n",
    "print('accuracy: ' + str(tree_model.score(X_test,Y_test)))\n",
    "print('spearman: ' + str(spearmanr(Y_test,Y_pred)[0]))\n",
    "print('cv score: ' + str(tree_model_cv))\n",
    "print('cv spear: ' + str(tree_model_cvspear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.22180673402695653\n",
      "accuracy: 0.1309745119686473\n",
      "spearman: 0.3371363882620885\n",
      "cv score: 0.318037411209186\n",
      "cv spear: 0.5146032414169597\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(999)\n",
    "forest_model = RandomForestRegressor(max_features=10,n_estimators=100, bootstrap=False,random_state = 999)\n",
    "forest_model.fit(X_train, Y_train.values.ravel())\n",
    "Y_pred = forest_model.predict(X_test)\n",
    "\n",
    "forest_model_mse = mean_squared_error(Y_test, Y_pred)\n",
    "forest_model_spear = spearmanr(Y_test,Y_pred)[0]\n",
    "forest_model_cv = np.mean(cross_val_score(forest_model, X_train, Y_train.values.ravel(), cv=5))\n",
    "forest_model_cvspear = np.mean(cross_val_score(forest_model, X_train, Y_train.values.ravel(), cv=5,scoring=make_scorer(spear_r)))\n",
    "\n",
    "print('mse: ' + str(mean_squared_error(Y_test, Y_pred)))\n",
    "print('accuracy: ' + str(forest_model.score(X_test,Y_test)))\n",
    "print('spearman: ' + str(spearmanr(Y_test,Y_pred)[0]))\n",
    "print('cv score: ' + str(forest_model_cv))\n",
    "print('cv spear: ' + str(forest_model_cvspear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.21787572260082727\n",
      "accuracy: 0.14637597909738487\n",
      "spearman: 0.3212711464615196\n",
      "cv score: 0.29163697492825086\n",
      "cv spear: 0.6317686375066041\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(colsample_bytree=0.4, gamma=0, learning_rate=0.07, max_depth=3, min_child_weight=1.5,\\\n",
    "                 n_estimators=10000, reg_alpha=0.75, reg_lambda=0.45, subsample=0.6, seed=42)\n",
    "xgb_model.fit(X_train, Y_train.values.ravel())\n",
    "Y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "xgb_model_mse = mean_squared_error(Y_test, Y_pred)\n",
    "xgb_model_spear = spearmanr(Y_test,Y_pred)[0]\n",
    "xgb_model_cv = np.mean(cross_val_score(xgb_model, X_train, Y_train.values.ravel(), cv=5))\n",
    "xgb_model_cvspear = np.mean(cross_val_score(xgb_model, X_train, Y_train.values.ravel(), cv=5,scoring=make_scorer(spear_r)))\n",
    "\n",
    "print('mse: ' + str(mean_squared_error(Y_test, Y_pred)))\n",
    "print('accuracy: ' + str(xgb_model.score(X_test,Y_test)))\n",
    "print('spearman: ' + str(spearmanr(Y_test,Y_pred)[0]))\n",
    "print('cv score: ' + str(xgb_model_cv))\n",
    "print('cv spear: ' + str(xgb_model_cvspear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8. AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.20688111683807886\n",
      "accuracy: 0.1894521854199737\n",
      "spearman: 0.24969135422340685\n",
      "cv score: 0.24450024937428655\n",
      "cv spear: 0.4128903022267096\n"
     ]
    }
   ],
   "source": [
    "ada_model = AdaBoostRegressor(random_state=0, n_estimators=200)\n",
    "ada_model.fit(X_train, Y_train.values.ravel())\n",
    "Y_pred = ada_model.predict(X_test)\n",
    "\n",
    "ada_model_mse = mean_squared_error(Y_test, Y_pred)\n",
    "ada_model_spear = spearmanr(Y_test,Y_pred)[0]\n",
    "ada_model_cv = np.mean(cross_val_score(ada_model, X_train, Y_train.values.ravel(), cv=5))\n",
    "ada_model_cvspear = np.mean(cross_val_score(ada_model, X_train, Y_train.values.ravel(), cv=5,scoring=make_scorer(spear_r)))\n",
    "\n",
    "print('mse: ' + str(mean_squared_error(Y_test, Y_pred)))\n",
    "print('accuracy: ' + str(ada_model.score(X_test,Y_test)))\n",
    "print('spearman: ' + str(spearmanr(Y_test,Y_pred)[0]))\n",
    "print('cv score: ' + str(ada_model_cv))\n",
    "print('cv spear: ' + str(ada_model_cvspear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9. Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.25973560969409804\n",
      "accuracy: -0.017628549303208896\n",
      "spearman: 0.43861850695954263\n",
      "cv score: -0.9489951935741144\n",
      "cv spear: 0.34554517395172907\n"
     ]
    }
   ],
   "source": [
    "gb_model = GradientBoostingRegressor(loss='quantile', n_estimators=50)\n",
    "gb_model.fit(X_train, Y_train.values.ravel())\n",
    "Y_pred = gb_model.predict(X_test)\n",
    "\n",
    "gb_model_mse = mean_squared_error(Y_test, Y_pred)\n",
    "gb_model_spear = spearmanr(Y_test,Y_pred)[0]\n",
    "gb_model_cv = np.mean(cross_val_score(gb_model, X_train, Y_train.values.ravel(), cv=5))\n",
    "gb_model_cvspear = np.mean(cross_val_score(gb_model, X_train, Y_train.values.ravel(), cv=5,scoring=make_scorer(spear_r)))\n",
    "\n",
    "print('mse: ' + str(mean_squared_error(Y_test, Y_pred)))\n",
    "print('accuracy: ' + str(gb_model.score(X_test,Y_test)))\n",
    "print('spearman: ' + str(spearmanr(Y_test,Y_pred)[0]))\n",
    "print('cv score: ' + str(gb_model_cv))\n",
    "print('cv spear: ' + str(gb_model_cvspear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = pd.DataFrame([['Linear', linear_model.score(X_test,Y_test),linear_model_spear,linear_model_cv,linear_model_cvspear,linear_model_mse], \\\n",
    "                      ['SVR', svr_model.score(X_test,Y_test),svr_model_spear,svr_model_cv,svr_model_cvspear,svr_model_mse], \\\n",
    "                      ['K Nearest Neighbors', knn_model.score(X_test,Y_test),knn_model_spear,knn_model_cv,knn_model_cvspear,knn_model_mse], \\\n",
    "                      ['Decision Tree',tree_model.score(X_test,Y_test),tree_model_spear,tree_model_cv,tree_model_cvspear,tree_model_mse], \\\n",
    "                      ['Random Forest', forest_model.score(X_test,Y_test),forest_model_spear,forest_model_cv,forest_model_cvspear,forest_model_mse], \\\n",
    "                      ['XGBoost', xgb_model.score(X_test,Y_test),xgb_model_spear,xgb_model_cv,xgb_model_cvspear,xgb_model_mse], \\\n",
    "                      ['AdaBoost', ada_model.score(X_test,Y_test),ada_model_spear,ada_model_cv,ada_model_cvspear,ada_model_mse], \\\n",
    "                      ['Gradient Boost', gb_model.score(X_test,Y_test),gb_model_spear,gb_model_cv,gb_model_cvspear,gb_model_mse]])\n",
    "models.columns = ['Model', 'Test Score','Spearman', 'CV score', 'Spearman CV', 'MSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Spearman</th>\n",
       "      <th>CV score</th>\n",
       "      <th>Spearman CV</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>-0.247874</td>\n",
       "      <td>0.476949</td>\n",
       "      <td>-0.109977</td>\n",
       "      <td>0.424083</td>\n",
       "      <td>0.318503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.425123</td>\n",
       "      <td>0.511158</td>\n",
       "      <td>0.349067</td>\n",
       "      <td>0.582929</td>\n",
       "      <td>0.146729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>0.325816</td>\n",
       "      <td>0.367380</td>\n",
       "      <td>0.354122</td>\n",
       "      <td>0.609680</td>\n",
       "      <td>0.172076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-1.632877</td>\n",
       "      <td>0.022377</td>\n",
       "      <td>0.027999</td>\n",
       "      <td>0.380979</td>\n",
       "      <td>0.672006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.130975</td>\n",
       "      <td>0.337136</td>\n",
       "      <td>0.318037</td>\n",
       "      <td>0.514603</td>\n",
       "      <td>0.221807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.146376</td>\n",
       "      <td>0.321271</td>\n",
       "      <td>0.291637</td>\n",
       "      <td>0.631769</td>\n",
       "      <td>0.217876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.189452</td>\n",
       "      <td>0.249691</td>\n",
       "      <td>0.244500</td>\n",
       "      <td>0.412890</td>\n",
       "      <td>0.206881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>-0.017629</td>\n",
       "      <td>0.438619</td>\n",
       "      <td>-0.948995</td>\n",
       "      <td>0.345545</td>\n",
       "      <td>0.259736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Test Score  Spearman  CV score  Spearman CV       MSE\n",
       "0               Linear   -0.247874  0.476949 -0.109977     0.424083  0.318503\n",
       "1                  SVR    0.425123  0.511158  0.349067     0.582929  0.146729\n",
       "2  K Nearest Neighbors    0.325816  0.367380  0.354122     0.609680  0.172076\n",
       "3        Decision Tree   -1.632877  0.022377  0.027999     0.380979  0.672006\n",
       "4        Random Forest    0.130975  0.337136  0.318037     0.514603  0.221807\n",
       "5              XGBoost    0.146376  0.321271  0.291637     0.631769  0.217876\n",
       "6             AdaBoost    0.189452  0.249691  0.244500     0.412890  0.206881\n",
       "7       Gradient Boost   -0.017629  0.438619 -0.948995     0.345545  0.259736"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: SVR performs best for Test Score, Spearman, and MSE. XGBoost performs best for Spearman CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3]",
   "language": "python",
   "name": "conda-env-miniconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
